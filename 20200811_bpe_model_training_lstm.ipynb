{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the codeSearchNetChallenge dataset \n",
    "_If needed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeSearchNet challenge dataset ready to use!\n"
     ]
    }
   ],
   "source": [
    "%run downloading_cleaning_codeSearchNetChallenge_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the codeSearchNetChallenge dataset to CSV files\n",
    "\n",
    "_If needed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines of Python code in the dataset (after removing empty lines)\n",
      "11206193\n",
      "\n",
      "\n",
      "Total lines of Python code in the dataset's train folder (after removing empty lines)\n",
      "10054266\n",
      "\n",
      "\n",
      "Total lines of Python in the dataset's test folder (after removing empty lines)\n",
      "541338\n",
      "\n",
      "\n",
      "Total lines of Python in the dataset's valid folder\n",
      "610589\n"
     ]
    }
   ],
   "source": [
    "%run preparing_csv_files_from_codeSearchNetChallenge_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training tokenizer using SentencePiece\n",
    "\n",
    "_model_type=bpe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device in use:  0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print ('Current cuda device in use: ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import sentencepiece as spm #https://github.com/google/sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 600\n",
    "model_prefix = 'bpe_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeSearchNet_challenge_path = './CodeSearchNet_challenge_dataset'\n",
    "all_csv_path = './CodeSearchNet_challenge_dataset/CodeSearchNet_challenge_dataset.csv'\n",
    "train_csv_path = './CodeSearchNet_challenge_dataset/python/final/jsonl/train/train_CodeSearchNet_challenge_dataset.csv'\n",
    "test_csv_path = './CodeSearchNet_challenge_dataset/python/final/jsonl/test/test_CodeSearchNet_challenge_dataset.csv'\n",
    "valid_csv_path = './CodeSearchNet_challenge_dataset/python/final/jsonl/valid/valid_CodeSearchNet_challenge_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(f'--input={all_csv_path}'\\\n",
    "                               f' --model_prefix={model_prefix}'\\\n",
    "                               f' --vocab_size={vocab_size}'\\\n",
    "                               f' --model_type=bpe'\\\n",
    "                               f' --unk_piece={UNK} --bos_piece={BOS} --eos_id=-1 --pad_piece={PAD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load up the Processor\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(f'{model_prefix}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = []\n",
    "with open(f'{model_prefix}.vocab','r') as f:\n",
    "    for line_num,line in enumerate(f):\n",
    "        itos.append(line.split(\"\\t\")[0])\n",
    "\n",
    "class SPTokenizer(BaseTokenizer):\n",
    "    \"Wrapper around a SentncePiece tokenizer to make it a `BaseTokenizer`.\"\n",
    "    def __init__(self, model_prefix:str):\n",
    "        self.tok = spm.SentencePieceProcessor()\n",
    "        self.tok.load(f'{model_prefix}.model')\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.tok.EncodeAsPieces(t)\n",
    "    \n",
    "class CustomTokenizer():\n",
    "    '''Wrapper for SentencePiece toeknizer to fit into Fast.ai V1'''\n",
    "    def __init__(self,tok_func:Callable,model_prefix:str, pre_rules:ListRules=None):\n",
    "        self.tok_func,self.model_prefix = tok_func,model_prefix\n",
    "        self.pre_rules  = ifnone(pre_rules,  defaults.text_pre_rules )\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        res = f'Tokenizer {self.tok_func.__name__} using `{self.model_prefix}` model with the following rules:\\n'\n",
    "        for rule in self.pre_rules: res += f' - {rule.__name__}\\n'\n",
    "        return res        \n",
    "\n",
    "    def process_text(self, t:str,tok:BaseTokenizer) -> List[str]:\n",
    "        \"Processe one text `t` with tokenizer `tok`.\"\n",
    "        for rule in self.pre_rules: t = rule(t)  \n",
    "        toks = tok.tokenizer(t)\n",
    "        #post rules?\n",
    "        return toks \n",
    "    \n",
    "    def _process_all_1(self,texts:Collection[str]) -> List[List[str]]:\n",
    "        'Process a list of `texts` in one process'\n",
    "        tok = self.tok_func(self.model_prefix)\n",
    "        return [self.process_text(t,tok) for t in texts]\n",
    "                                                                     \n",
    "    def process_all(self, texts:Collection[str]) -> List[List[str]]: \n",
    "        \"Process a list of `texts`.\"                                 \n",
    "        return self._process_all_1(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycust_tok = CustomTokenizer(SPTokenizer, model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Vocab object for use in LM\n",
    "sp_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(a, dtype=dtype, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = TextLMDataBunch.from_csv('./', train_csv_path, test=test_csv_path, tokenizer=mycust_tok, vocab=sp_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  idx_min = (t != self.pad_idx).nonzero().min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>er ▁l ine , ▁w r ite ▁e a ch ▁ro w ▁to ▁the ▁g iv en ▁in put ▁file ▁with ▁fi eld s ▁se par ated ▁by ▁t a b s . ▁: type ▁m ap F N H : ▁file ▁or ▁str ▁: param ▁m ap F N H : ▁E ith er ▁the ▁f ul l ▁path ▁to ▁the ▁m ap ▁file ▁or ▁an ▁o p en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>t : b ro ca de - v c s ', ▁def in ing _ m od ule =' b ro ca de - v c s ', ▁y an g _ type =' r p c ', ▁is _ con fig = True ) \"\" \" , ▁ } ) ▁self ._ _ get _ v c s _ de ta il s ▁= ▁t ▁if ▁h as at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁h as ▁the ▁s ame ▁time ▁s cal e ▁as ▁the ▁fi r st ▁ one ▁( t he ▁t w o ▁p lo ts ▁are ▁s y n ch r on iz ed ), ▁be ing ▁p lo t t ed ▁the ▁e v ol ut ion ▁time ▁se ri es ▁of ▁E M G ▁me di an ▁f re qu en c y . ▁P er ▁m us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>as ▁# ▁re mo v ed ▁in ▁the ▁a bo ve ▁c ode ▁f ra g ment ▁al read y . ▁key se qu en ce ▁= ▁key se qu en ce [ : - 1 ] ▁# ▁N ow ▁s u c cess iv el y ▁re mo ve ▁the ▁key ▁se qu en ce ▁in ▁re ver se ▁or der . ▁wh ile ( len ( key se</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>s ▁to ▁s h ort ▁ch ar s . ▁\"\" \" ▁out ▁= ▁'' ▁for ▁ch ar ▁in ▁ch ar s : ▁if ▁ch ar ▁in ▁_ c d . B I G 5 : ▁out ▁+ = ▁_ c d . G B K [ _ c d . B I G 5 . in dex ( ch ar ) ] ▁else : ▁out ▁+ = ▁ch ar ▁return</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save('20200811_bpe_model_databunch_data_save.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "data = load_data('./', '20200811_bpe_model_databunch_data_save.pkl', bs=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialRNN(\n",
      "  (0): AWD_LSTM(\n",
      "    (encoder): Embedding(600, 400, padding_idx=1)\n",
      "    (encoder_dp): EmbeddingDropout(\n",
      "      (emb): Embedding(600, 400, padding_idx=1)\n",
      "    )\n",
      "    (rnns): ModuleList(\n",
      "      (0): WeightDropout(\n",
      "        (module): LSTM(400, 1152, batch_first=True)\n",
      "      )\n",
      "      (1): WeightDropout(\n",
      "        (module): LSTM(1152, 1152, batch_first=True)\n",
      "      )\n",
      "      (2): WeightDropout(\n",
      "        (module): LSTM(1152, 400, batch_first=True)\n",
      "      )\n",
      "    )\n",
      "    (input_dp): RNNDropout()\n",
      "    (hidden_dps): ModuleList(\n",
      "      (0): RNNDropout()\n",
      "      (1): RNNDropout()\n",
      "      (2): RNNDropout()\n",
      "    )\n",
      "  )\n",
      "  (1): LinearDecoder(\n",
      "    (decoder): Linear(in_features=400, out_features=600, bias=True)\n",
      "    (output_dp): RNNDropout()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "RNNDropout           [70, 400]            0          False     \n",
       "______________________________________________________________________\n",
       "RNNDropout           [70, 1152]           0          False     \n",
       "______________________________________________________________________\n",
       "RNNDropout           [70, 1152]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [70, 600]            240,600    True      \n",
       "______________________________________________________________________\n",
       "RNNDropout           [70, 400]            0          False     \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 240,600\n",
       "Total trainable params: 240,600\n",
       "Total non-trainable params: 0\n",
       "Optimized with 'torch.optim.adam.Adam', betas=(0.9, 0.99)\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    RNNTrainer"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='99' class='' max='1231', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      8.04% [99/1231 01:23<16:00 8.6268]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 5.75E-02\n",
      "Min loss divided by 10: 1.58E-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.328326</td>\n",
       "      <td>3.122928</td>\n",
       "      <td>0.314351</td>\n",
       "      <td>19:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, slice(1e-1, 1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('20200811_fit_head_bpe_model_drop_mult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('20200811_fit_head_bpe_model_drop_mult');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.928001</td>\n",
       "      <td>1.996182</td>\n",
       "      <td>0.520855</td>\n",
       "      <td>28:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.850428</td>\n",
       "      <td>1.950834</td>\n",
       "      <td>0.529625</td>\n",
       "      <td>29:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.874266</td>\n",
       "      <td>1.978287</td>\n",
       "      <td>0.523630</td>\n",
       "      <td>29:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.936947</td>\n",
       "      <td>2.023138</td>\n",
       "      <td>0.516128</td>\n",
       "      <td>29:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.962458</td>\n",
       "      <td>2.054753</td>\n",
       "      <td>0.510439</td>\n",
       "      <td>28:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.975345</td>\n",
       "      <td>2.080720</td>\n",
       "      <td>0.505472</td>\n",
       "      <td>28:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.999894</td>\n",
       "      <td>2.081296</td>\n",
       "      <td>0.505816</td>\n",
       "      <td>28:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.983418</td>\n",
       "      <td>2.079545</td>\n",
       "      <td>0.506184</td>\n",
       "      <td>28:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.963275</td>\n",
       "      <td>2.058214</td>\n",
       "      <td>0.510210</td>\n",
       "      <td>28:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.936085</td>\n",
       "      <td>2.029901</td>\n",
       "      <td>0.515913</td>\n",
       "      <td>28:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.917196</td>\n",
       "      <td>2.014891</td>\n",
       "      <td>0.518762</td>\n",
       "      <td>28:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.887311</td>\n",
       "      <td>1.989071</td>\n",
       "      <td>0.523959</td>\n",
       "      <td>28:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.866707</td>\n",
       "      <td>1.965362</td>\n",
       "      <td>0.527716</td>\n",
       "      <td>28:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.846387</td>\n",
       "      <td>1.945072</td>\n",
       "      <td>0.531434</td>\n",
       "      <td>28:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.810108</td>\n",
       "      <td>1.921329</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>28:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.802546</td>\n",
       "      <td>1.901778</td>\n",
       "      <td>0.539982</td>\n",
       "      <td>28:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.775946</td>\n",
       "      <td>1.882680</td>\n",
       "      <td>0.543361</td>\n",
       "      <td>28:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.759848</td>\n",
       "      <td>1.859895</td>\n",
       "      <td>0.547940</td>\n",
       "      <td>28:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.738717</td>\n",
       "      <td>1.840156</td>\n",
       "      <td>0.551875</td>\n",
       "      <td>28:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.726963</td>\n",
       "      <td>1.819566</td>\n",
       "      <td>0.555633</td>\n",
       "      <td>28:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.695719</td>\n",
       "      <td>1.799364</td>\n",
       "      <td>0.559859</td>\n",
       "      <td>28:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.670356</td>\n",
       "      <td>1.780053</td>\n",
       "      <td>0.563531</td>\n",
       "      <td>28:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.661808</td>\n",
       "      <td>1.761775</td>\n",
       "      <td>0.567222</td>\n",
       "      <td>28:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.633117</td>\n",
       "      <td>1.747741</td>\n",
       "      <td>0.570612</td>\n",
       "      <td>28:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.610914</td>\n",
       "      <td>1.734928</td>\n",
       "      <td>0.573587</td>\n",
       "      <td>28:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.597136</td>\n",
       "      <td>1.721189</td>\n",
       "      <td>0.576243</td>\n",
       "      <td>28:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.580360</td>\n",
       "      <td>1.712532</td>\n",
       "      <td>0.578177</td>\n",
       "      <td>28:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.564023</td>\n",
       "      <td>1.705756</td>\n",
       "      <td>0.579727</td>\n",
       "      <td>28:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.567405</td>\n",
       "      <td>1.703645</td>\n",
       "      <td>0.580342</td>\n",
       "      <td>28:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.561393</td>\n",
       "      <td>1.703536</td>\n",
       "      <td>0.580373</td>\n",
       "      <td>28:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(30, slice(1e-1, 1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('20200811_fine_tuned_bpe_model_drop_mult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('20200811_fine_tuned_bpe_model_drop_mult');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import from the XML and AppList to the given implementation. item_\n",
      "import from XXX modules = [] return [impl.set_import(map\n",
      "import from create_packages on XML registry XMLPackage.\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"import from\"\n",
    "N_WORDS = 25\n",
    "N_SENTENCES = 3\n",
    "for _ in range(N_SENTENCES):\n",
    "    predicted = learn.predict(TEXT, N_WORDS, temperature=0.9)\n",
    "    val = predicted.replace(TEXT, '')\n",
    "    decoded = sp.decode_pieces(val.split())\n",
    "    print(TEXT + \" \"+  decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialRNN\n",
      "======================================================================\n",
      "Layer (type)         Output Shape         Param #    Trainable \n",
      "======================================================================\n",
      "RNNDropout           [70, 400]            0          False     \n",
      "______________________________________________________________________\n",
      "RNNDropout           [70, 1152]           0          False     \n",
      "______________________________________________________________________\n",
      "RNNDropout           [70, 1152]           0          False     \n",
      "______________________________________________________________________\n",
      "Linear               [70, 600]            240,600    True      \n",
      "______________________________________________________________________\n",
      "RNNDropout           [70, 400]            0          False     \n",
      "______________________________________________________________________\n",
      "\n",
      "Total params: 240,600\n",
      "Total trainable params: 240,600\n",
      "Total non-trainable params: 0\n",
      "Optimized with 'torch.optim.adam.Adam', betas=(0.9, 0.99)\n",
      "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
      "Loss function : FlattenedLoss\n",
      "======================================================================\n",
      "Callbacks functions applied \n",
      "    RNNTrainer\n"
     ]
    }
   ],
   "source": [
    "print(learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pandas import parse_xyz from sqlalchemy.orm.elements.types i\n",
      "from pandas import DataFrame import io class FindHierarchy(str): run\n",
      "from pandas import iterer as gps_procs import numpy as np data = np.ren\n",
      "from pandas import TranslationLogic instances = [HT_LIST_VAL\n",
      "from pandas import PandasPandas # Convert to XSD for reading. input_in\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"from pandas import\"\n",
    "N_WORDS = 25\n",
    "N_SENTENCES = 5\n",
    "for _ in range(N_SENTENCES):\n",
    "    predicted = learn.predict(TEXT, N_WORDS, temperature=0.9)\n",
    "    val = predicted.replace(TEXT, '')\n",
    "    decoded = sp.decode_pieces(val.split())\n",
    "    print(TEXT + \" \"+  decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
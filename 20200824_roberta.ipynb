{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the codeSearchNetChallenge dataset \n",
    "_If needed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeSearchNet challenge dataset ready to use!\n"
     ]
    }
   ],
   "source": [
    "%run downloading_cleaning_codeSearchNetChallenge_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the codeSearchNetChallenge dataset to CSV files\n",
    "\n",
    "_If needed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines of Python code in the dataset (after removing empty lines)\n",
      "11206193\n",
      "\n",
      "\n",
      "Total lines of Python code in the dataset's train folder (after removing empty lines)\n",
      "10054266\n",
      "\n",
      "\n",
      "Total lines of Python in the dataset's test folder (after removing empty lines)\n",
      "541338\n",
      "\n",
      "\n",
      "Total lines of Python in the dataset's valid folder\n",
      "610589\n"
     ]
    }
   ],
   "source": [
    "%run preparing_csv_files_from_codeSearchNetChallenge_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://dev.fast.ai/tutorial.transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'roberta-base'\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(pretrained_weights)\n",
    "model = RobertaForMaskedLM.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 713, 16, 41, 1246, 9, 2788, 6, 8, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode('This is an example of text, and')\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>This is an example of text, and</s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.LongTensor(ids)[None]\n",
    "preds = model.generate(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 11]),\n",
       " tensor([   0,  713,   16,   41, 1246,    9, 2788,    6,    8,    2,    2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape,preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>This is an example of text, and</s></s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeSearchNet_challenge_path = './CodeSearchNet_challenge_dataset'\n",
    "all_csv_path = './CodeSearchNet_challenge_dataset/CodeSearchNet_challenge_dataset.csv'\n",
    "train_csv_path = './CodeSearchNet_challenge_dataset/python/final/jsonl/train/train_CodeSearchNet_challenge_dataset.csv'\n",
    "test_csv_path = './CodeSearchNet_challenge_dataset/python/final/jsonl/test/test_CodeSearchNet_challenge_dataset.csv'\n",
    "valid_csv_path = './CodeSearchNet_challenge_dataset/python/final/jsonl/valid/valid_CodeSearchNet_challenge_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_11.py</td>\n",
       "      <td>def show_slug_with_level(context, page, lang=None, fallback=True):\\n    \"\"\"Display slug with level by language.\"\"\"\\n    if not lang:\\n        lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\\n\\n    page = get_page_from_string_or_id(page, lang)\\n    if not page:\\n        return ''\\n\\n    return {'content': page.slug_with_level(lang)}\\n\\n\\ndef show_revisions(context, page, content_type, lang=None):\\n    \"\"\"Render the last 10 revisions of a page content with a list using\\n        the ``pages/revisions.html`` template\"\"\"\\n    if not pages_settings.PAGE_CONTENT_REVISION:\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_8.py</td>\n",
       "      <td>def public(self):\\n    \"\"\"True if the Slot is public.\"\"\"\\n    return bool(lib.EnvSlotPublicP(self._env, self._cls, self._name))\\n\\n\\ndef initializable(self):\\n    \"\"\"True if the Slot is initializable.\"\"\"\\n    return bool(lib.EnvSlotInitableP(self._env, self._cls, self._name))\\n\\n\\ndef writable(self):\\n    \"\"\"True if the Slot is writable.\"\"\"\\n    return bool(lib.EnvSlotWritableP(self._env, self._cls, self._name))\\n\\n\\ndef accessible(self):\\n    \"\"\"True if the Slot is directly accessible.\"\"\"\\n    return bool(lib.EnvSlotDirectAccessP(self._env, self._cls, self._name))\\n\\n\\ndef types(self):\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_1.py</td>\n",
       "      <td>def zmq_device(self):\\n    '''\\n    Multiprocessing target for the zmq queue device\\n    '''\\n    self.__setup_signals()\\n    salt.utils.process.appendproctitle('MWorkerQueue')\\n    self.context = zmq.Context(self.opts['worker_threads'])\\n    # Prepare the zeromq sockets\\n    self.uri = 'tcp://{interface}:{ret_port}'.format(**self.opts)\\n    self.clients = self.context.socket(zmq.ROUTER)\\n    if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\\n        # IPv6 sockets work for both IPv6 and IPv4 addresses\\n        self.clients.setsockopt(zmq.IPV4ONLY, 0)\\n    self.clients.setsockopt(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_13.py</td>\n",
       "      <td>def get_datetime_sorted_rows(dbconn, table_name, uuid=None, column=None):\\n    \"\"\"\\n    Get a list of datetime sorted rows from a table in the database\\n    :param dbconn: database connection\\n    :param table_name: name of table in the database\\n    :param uuid: optional uuid to pull from\\n    :param column: optional column/field in the table to pull instead of rows\\n    :returns: a list of tuples containing (datetime, row) pairs or (datetime, column) pairs if columns is specified.\\n    \"\"\"\\n    rows = get_rows(dbconn, table_name, uuid=uuid)\\n    data = []\\n    for r in rows:\\n        dt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_5.py</td>\n",
       "      <td>def export_ruptures_csv(ekey, dstore):\\n    \"\"\"\\n    :param ekey: export key, i.e. a pair (datastore key, fmt)\\n    :param dstore: datastore object\\n    \"\"\"\\n    oq = dstore['oqparam']\\n    if 'scenario' in oq.calculation_mode:\\n        return []\\n    dest = dstore.export_path('ruptures.csv')\\n    header = ('rupid multiplicity mag centroid_lon centroid_lat '\\n              'centroid_depth trt strike dip rake boundary').split()\\n    rows = []\\n    for rgetter in gen_rupture_getters(dstore):\\n        rups = rgetter.get_ruptures()\\n        rup_data = calc.RuptureData(rgetter.trt, rgetter.rlzs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      filename  \\\n",
       "0  CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_11.py   \n",
       "1   CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_8.py   \n",
       "2   CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_1.py   \n",
       "3  CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_13.py   \n",
       "4   CodeSearchNet_challenge_dataset/python/final/jsonl/train/python_train_5.py   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  def show_slug_with_level(context, page, lang=None, fallback=True):\\n    \"\"\"Display slug with level by language.\"\"\"\\n    if not lang:\\n        lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\\n\\n    page = get_page_from_string_or_id(page, lang)\\n    if not page:\\n        return ''\\n\\n    return {'content': page.slug_with_level(lang)}\\n\\n\\ndef show_revisions(context, page, content_type, lang=None):\\n    \"\"\"Render the last 10 revisions of a page content with a list using\\n        the ``pages/revisions.html`` template\"\"\"\\n    if not pages_settings.PAGE_CONTENT_REVISION:\\n      ...  \n",
       "1  def public(self):\\n    \"\"\"True if the Slot is public.\"\"\"\\n    return bool(lib.EnvSlotPublicP(self._env, self._cls, self._name))\\n\\n\\ndef initializable(self):\\n    \"\"\"True if the Slot is initializable.\"\"\"\\n    return bool(lib.EnvSlotInitableP(self._env, self._cls, self._name))\\n\\n\\ndef writable(self):\\n    \"\"\"True if the Slot is writable.\"\"\"\\n    return bool(lib.EnvSlotWritableP(self._env, self._cls, self._name))\\n\\n\\ndef accessible(self):\\n    \"\"\"True if the Slot is directly accessible.\"\"\"\\n    return bool(lib.EnvSlotDirectAccessP(self._env, self._cls, self._name))\\n\\n\\ndef types(self):\\n ...  \n",
       "2  def zmq_device(self):\\n    '''\\n    Multiprocessing target for the zmq queue device\\n    '''\\n    self.__setup_signals()\\n    salt.utils.process.appendproctitle('MWorkerQueue')\\n    self.context = zmq.Context(self.opts['worker_threads'])\\n    # Prepare the zeromq sockets\\n    self.uri = 'tcp://{interface}:{ret_port}'.format(**self.opts)\\n    self.clients = self.context.socket(zmq.ROUTER)\\n    if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\\n        # IPv6 sockets work for both IPv6 and IPv4 addresses\\n        self.clients.setsockopt(zmq.IPV4ONLY, 0)\\n    self.clients.setsockopt(...  \n",
       "3  def get_datetime_sorted_rows(dbconn, table_name, uuid=None, column=None):\\n    \"\"\"\\n    Get a list of datetime sorted rows from a table in the database\\n    :param dbconn: database connection\\n    :param table_name: name of table in the database\\n    :param uuid: optional uuid to pull from\\n    :param column: optional column/field in the table to pull instead of rows\\n    :returns: a list of tuples containing (datetime, row) pairs or (datetime, column) pairs if columns is specified.\\n    \"\"\"\\n    rows = get_rows(dbconn, table_name, uuid=uuid)\\n    data = []\\n    for r in rows:\\n        dt ...  \n",
       "4  def export_ruptures_csv(ekey, dstore):\\n    \"\"\"\\n    :param ekey: export key, i.e. a pair (datastore key, fmt)\\n    :param dstore: datastore object\\n    \"\"\"\\n    oq = dstore['oqparam']\\n    if 'scenario' in oq.calculation_mode:\\n        return []\\n    dest = dstore.export_path('ruptures.csv')\\n    header = ('rupid multiplicity mag centroid_lon centroid_lat '\\n              'centroid_depth trt strike dip rake boundary').split()\\n    rows = []\\n    for rgetter in gen_rupture_getters(dstore):\\n        rups = rgetter.get_ruptures()\\n        rup_data = calc.RuptureData(rgetter.trt, rgetter.rlzs...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_csv_path)\n",
    "df_valid = pd.read_csv(test_csv_path)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def show_slug_with_level(context, page, lang=None, fallback=True):\\n    \"\"\"Display slug with level by language.\"\"\"\\n    if not lang:\\n        lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\\n\\n    page = get_page_from_string_or_id(page, lang)\\n    if not page:\\n        return ''\\n\\n    return {'content': page.slug_with_level(lang)}\\n\\n\\ndef show_revisions(context, page, content_type, lang=None):\\n    \"\"\"Render the last 10 revisions of a page content with a list using\\n        the ``pages/revisions.html`` template\"\"\"\\n    if not pages_settings.PAGE_CONTENT_REVISION:\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def public(self):\\n    \"\"\"True if the Slot is public.\"\"\"\\n    return bool(lib.EnvSlotPublicP(self._env, self._cls, self._name))\\n\\n\\ndef initializable(self):\\n    \"\"\"True if the Slot is initializable.\"\"\"\\n    return bool(lib.EnvSlotInitableP(self._env, self._cls, self._name))\\n\\n\\ndef writable(self):\\n    \"\"\"True if the Slot is writable.\"\"\"\\n    return bool(lib.EnvSlotWritableP(self._env, self._cls, self._name))\\n\\n\\ndef accessible(self):\\n    \"\"\"True if the Slot is directly accessible.\"\"\"\\n    return bool(lib.EnvSlotDirectAccessP(self._env, self._cls, self._name))\\n\\n\\ndef types(self):\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def zmq_device(self):\\n    '''\\n    Multiprocessing target for the zmq queue device\\n    '''\\n    self.__setup_signals()\\n    salt.utils.process.appendproctitle('MWorkerQueue')\\n    self.context = zmq.Context(self.opts['worker_threads'])\\n    # Prepare the zeromq sockets\\n    self.uri = 'tcp://{interface}:{ret_port}'.format(**self.opts)\\n    self.clients = self.context.socket(zmq.ROUTER)\\n    if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\\n        # IPv6 sockets work for both IPv6 and IPv4 addresses\\n        self.clients.setsockopt(zmq.IPV4ONLY, 0)\\n    self.clients.setsockopt(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def get_datetime_sorted_rows(dbconn, table_name, uuid=None, column=None):\\n    \"\"\"\\n    Get a list of datetime sorted rows from a table in the database\\n    :param dbconn: database connection\\n    :param table_name: name of table in the database\\n    :param uuid: optional uuid to pull from\\n    :param column: optional column/field in the table to pull instead of rows\\n    :returns: a list of tuples containing (datetime, row) pairs or (datetime, column) pairs if columns is specified.\\n    \"\"\"\\n    rows = get_rows(dbconn, table_name, uuid=uuid)\\n    data = []\\n    for r in rows:\\n        dt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def export_ruptures_csv(ekey, dstore):\\n    \"\"\"\\n    :param ekey: export key, i.e. a pair (datastore key, fmt)\\n    :param dstore: datastore object\\n    \"\"\"\\n    oq = dstore['oqparam']\\n    if 'scenario' in oq.calculation_mode:\\n        return []\\n    dest = dstore.export_path('ruptures.csv')\\n    header = ('rupid multiplicity mag centroid_lon centroid_lat '\\n              'centroid_depth trt strike dip rake boundary').split()\\n    rows = []\\n    for rgetter in gen_rupture_getters(dstore):\\n        rups = rgetter.get_ruptures()\\n        rup_data = calc.RuptureData(rgetter.trt, rgetter.rlzs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text\n",
       "0  def show_slug_with_level(context, page, lang=None, fallback=True):\\n    \"\"\"Display slug with level by language.\"\"\"\\n    if not lang:\\n        lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\\n\\n    page = get_page_from_string_or_id(page, lang)\\n    if not page:\\n        return ''\\n\\n    return {'content': page.slug_with_level(lang)}\\n\\n\\ndef show_revisions(context, page, content_type, lang=None):\\n    \"\"\"Render the last 10 revisions of a page content with a list using\\n        the ``pages/revisions.html`` template\"\"\"\\n    if not pages_settings.PAGE_CONTENT_REVISION:\\n      ...\n",
       "1  def public(self):\\n    \"\"\"True if the Slot is public.\"\"\"\\n    return bool(lib.EnvSlotPublicP(self._env, self._cls, self._name))\\n\\n\\ndef initializable(self):\\n    \"\"\"True if the Slot is initializable.\"\"\"\\n    return bool(lib.EnvSlotInitableP(self._env, self._cls, self._name))\\n\\n\\ndef writable(self):\\n    \"\"\"True if the Slot is writable.\"\"\"\\n    return bool(lib.EnvSlotWritableP(self._env, self._cls, self._name))\\n\\n\\ndef accessible(self):\\n    \"\"\"True if the Slot is directly accessible.\"\"\"\\n    return bool(lib.EnvSlotDirectAccessP(self._env, self._cls, self._name))\\n\\n\\ndef types(self):\\n ...\n",
       "2  def zmq_device(self):\\n    '''\\n    Multiprocessing target for the zmq queue device\\n    '''\\n    self.__setup_signals()\\n    salt.utils.process.appendproctitle('MWorkerQueue')\\n    self.context = zmq.Context(self.opts['worker_threads'])\\n    # Prepare the zeromq sockets\\n    self.uri = 'tcp://{interface}:{ret_port}'.format(**self.opts)\\n    self.clients = self.context.socket(zmq.ROUTER)\\n    if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\\n        # IPv6 sockets work for both IPv6 and IPv4 addresses\\n        self.clients.setsockopt(zmq.IPV4ONLY, 0)\\n    self.clients.setsockopt(...\n",
       "3  def get_datetime_sorted_rows(dbconn, table_name, uuid=None, column=None):\\n    \"\"\"\\n    Get a list of datetime sorted rows from a table in the database\\n    :param dbconn: database connection\\n    :param table_name: name of table in the database\\n    :param uuid: optional uuid to pull from\\n    :param column: optional column/field in the table to pull instead of rows\\n    :returns: a list of tuples containing (datetime, row) pairs or (datetime, column) pairs if columns is specified.\\n    \"\"\"\\n    rows = get_rows(dbconn, table_name, uuid=uuid)\\n    data = []\\n    for r in rows:\\n        dt ...\n",
       "4  def export_ruptures_csv(ekey, dstore):\\n    \"\"\"\\n    :param ekey: export key, i.e. a pair (datastore key, fmt)\\n    :param dstore: datastore object\\n    \"\"\"\\n    oq = dstore['oqparam']\\n    if 'scenario' in oq.calculation_mode:\\n        return []\\n    dest = dstore.export_path('ruptures.csv')\\n    header = ('rupid multiplicity mag centroid_lon centroid_lat '\\n              'centroid_depth trt strike dip rake boundary').split()\\n    rows = []\\n    for rgetter in gen_rupture_getters(dstore):\\n        rups = rgetter.get_ruptures()\\n        rup_data = calc.RuptureData(rgetter.trt, rgetter.rlzs..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def get_vid_from_url(url):\\n    \"\"\"Extracts video ID from URL.\\n    \"\"\"\\n    return match1(url, r'youtu\\.be/([^?/]+)') or \\\\n        match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/v/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\\n        parse_query_param(url, 'v') or \\\\n        parse_query_param(parse_query_param(url, 'u'), 'v')\\n\\n\\ndef sina_xml_to_url_list(xml_data):\\n    \"\"\"str-&gt;list\\n    Convert XML to URL List.\\n    From Biligrab.\\n    \"\"\"\\n    rawurl = []\\n    dom = parseString(xml_data)\\n    for node in dom.getElement...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text\n",
       "0  def get_vid_from_url(url):\\n    \"\"\"Extracts video ID from URL.\\n    \"\"\"\\n    return match1(url, r'youtu\\.be/([^?/]+)') or \\\\n        match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/v/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\\n        parse_query_param(url, 'v') or \\\\n        parse_query_param(parse_query_param(url, 'u'), 'v')\\n\\n\\ndef sina_xml_to_url_list(xml_data):\\n    \"\"\"str->list\\n    Convert XML to URL List.\\n    From Biligrab.\\n    \"\"\"\\n    rawurl = []\\n    dom = parseString(xml_data)\\n    for node in dom.getElement..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = df_train[[\"text\"]]\n",
    "df_valid = df_valid[[\"text\"]]\n",
    "\n",
    "display(df_train.head())\n",
    "display(df_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = np.concatenate([df_train[\"text\"].values, df_valid[\"text\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [list(range_of(df_train)), list(range(len(df_train), len(all_texts)))]\n",
    "tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 9232,   311,  1215,  ..., 43163,    43, 50118]),\n",
       " tensor([ 9232,   120,  1215,  ...,  1215, 25867, 50118]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tls.train[0],tls.valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11983775]), torch.Size([10037601]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tls.tfms(tls.train.items[0]).shape, tls.tfms(tls.valid.items[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_at(tls.train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_at(tls.valid, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 8,512\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def show_clock_output_clock_time_timezone(self, **kwargs):\\n    \"\"\"Auto Generated Code\\n    \"\"\"\\n    config = ET.Element(\"config\")\\n    show_clock = ET.Element(\"show_clock\")\\n    config = show_clock\\n    output = ET.SubElement(show_clock, \"output\")\\n    clock_time = ET.SubElement(output, \"clock-time\")\\n    timezone = ET.SubElement(clock_time, \"timezone\")\\n    timezone.text = kwargs.pop('timezone')\\n\\n    callback = kwargs.pop('callback', self._callback)\\n    return callback(config)\\n\\n\\ndef get_system_uptime_input_rbridge_id(self, **kwargs):\\n    \"\"\"Auto Generated Code\\n    \"\"\"\\n    config = ET.Element(\"config\")\\n    get_system_uptime = ET.Element(\"get_system_uptime\")\\n    config = get_system_uptime\\n    input = ET.SubElement(get_system_uptime, \"input\")\\n    rbridge_id = ET.SubElement(input, \"rbridge-id\")\\n    rbridge_id.text = kwargs.pop('rbridge_id')\\n\\n    callback = kwargs.pop('callback', self._callback)\\n    return callback(config)\\n\\n\\ndef get_system_uptime_output_show_system_uptime_rbridge_id(self, **kwargs):\\n    \"\"\"Auto Generated Code\\n    \"\"\"\\n    config = ET.Element(\"config\")\\n</td>\n",
       "      <td>show_clock_output_clock_time_timezone(self, **kwargs):\\n    \"\"\"Auto Generated Code\\n    \"\"\"\\n    config = ET.Element(\"config\")\\n    show_clock = ET.Element(\"show_clock\")\\n    config = show_clock\\n    output = ET.SubElement(show_clock, \"output\")\\n    clock_time = ET.SubElement(output, \"clock-time\")\\n    timezone = ET.SubElement(clock_time, \"timezone\")\\n    timezone.text = kwargs.pop('timezone')\\n\\n    callback = kwargs.pop('callback', self._callback)\\n    return callback(config)\\n\\n\\ndef get_system_uptime_input_rbridge_id(self, **kwargs):\\n    \"\"\"Auto Generated Code\\n    \"\"\"\\n    config = ET.Element(\"config\")\\n    get_system_uptime = ET.Element(\"get_system_uptime\")\\n    config = get_system_uptime\\n    input = ET.SubElement(get_system_uptime, \"input\")\\n    rbridge_id = ET.SubElement(input, \"rbridge-id\")\\n    rbridge_id.text = kwargs.pop('rbridge_id')\\n\\n    callback = kwargs.pop('callback', self._callback)\\n    return callback(config)\\n\\n\\ndef get_system_uptime_output_show_system_uptime_rbridge_id(self, **kwargs):\\n    \"\"\"Auto Generated Code\\n    \"\"\"\\n    config = ET.Element(\"config\")\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>through. This will succeed where the previous connection fails under\\n        the conditions of REMOTE_USER and galaxy running under uWSGI.\\n    \"\"\"\\n    history_id = history_id or os.environ['HISTORY_ID']\\n    key = os.environ['API_KEY']\\n\\n    ### Customised/Raw galaxy_url ###\\n    galaxy_ip = _get_ip()\\n    # Substitute $DOCKER_HOST with real IP\\n    url = Template(os.environ['GALAXY_URL']).safe_substitute(\\n        {'DOCKER_HOST': galaxy_ip})\\n    gi = _test_url(url, key, history_id, obj=obj)\\n    if gi is not None:\\n        return gi\\n\\n    ### Failover, fully auto-detected URL ###\\n    # Remove trailing slashes\\n    app_path = os.environ['GALAXY_URL'].rstrip('/')\\n    # Remove protocol+host:port if included\\n    app_path = ''.join(app_path.split('/')[3:])\\n\\n    if</td>\n",
       "      <td>through. This will succeed where the previous connection fails under\\n        the conditions of REMOTE_USER and galaxy running under uWSGI.\\n    \"\"\"\\n    history_id = history_id or os.environ['HISTORY_ID']\\n    key = os.environ['API_KEY']\\n\\n    ### Customised/Raw galaxy_url ###\\n    galaxy_ip = _get_ip()\\n    # Substitute $DOCKER_HOST with real IP\\n    url = Template(os.environ['GALAXY_URL']).safe_substitute(\\n        {'DOCKER_HOST': galaxy_ip})\\n    gi = _test_url(url, key, history_id, obj=obj)\\n    if gi is not None:\\n        return gi\\n\\n    ### Failover, fully auto-detected URL ###\\n    # Remove trailing slashes\\n    app_path = os.environ['GALAXY_URL'].rstrip('/')\\n    # Remove protocol+host:port if included\\n    app_path = ''.join(app_path.split('/')[3:])\\n\\n    if 'GALAXY_WEB_PORT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n    \"\"\"\\n    # decode the seed\\n    seed = encoder.decode(seed)\\n    # Verify the given seed type and size are correct\\n    if not (isinstance(seed, bytes) and len(seed) == cls.SEED_SIZE):\\n        raise exc.TypeError((\"PrivateKey seed must be a {0} bytes long \"\\n                             \"binary sequence\").format(cls.SEED_SIZE)\\n                            )\\n    # generate a raw keypair from the given seed\\n    raw_pk, raw_sk = nacl.bindings.crypto_box_seed_keypair(seed)\\n    # construct a instance from the raw secret key\\n</td>\n",
       "      <td>\"\"\"\\n    # decode the seed\\n    seed = encoder.decode(seed)\\n    # Verify the given seed type and size are correct\\n    if not (isinstance(seed, bytes) and len(seed) == cls.SEED_SIZE):\\n        raise exc.TypeError((\"PrivateKey seed must be a {0} bytes long \"\\n                             \"binary sequence\").format(cls.SEED_SIZE)\\n                            )\\n    # generate a raw keypair from the given seed\\n    raw_pk, raw_sk = nacl.bindings.crypto_box_seed_keypair(seed)\\n    # construct a instance from the raw secret key\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>}\\n                                      }\\n                                  },\\n                                  **kwargs)\\n    buckets = results['facets']['categories']['buckets']\\n</td>\n",
       "      <td>}\\n                                      }\\n                                  },\\n                                  **kwargs)\\n    buckets = results['facets']['categories']['buckets']\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.config['VUE_CONFIGURATION']))\\n    if not target:\\n        raise ValueError('Can not find resource from configuration.')\\n    target = target[0]\\n    use_minified = (isinstance(use_minified, bool) and use_minified) or current_app.config['VUE_USE_MINIFIED']\\n    CdnClass = LocalCDN if target['use_local'] else getattr(cdn, target['cdn'], CDN)\\n    resource_url = CdnClass(name=name, version=target.get('version', ''),\\n                            use_minified=use_minified).get_resource_url()\\n    if resource_url.startswith('//') and current_app.config['VUE_CDN_FORCE_SSL']:\\n        resource_url = 'https:%s' % resource_url\\n    return resource_url\\n\\ndef humantime(time):\\n    \"\"\"Converts a time in seconds to a reasonable human readable time\\n\\n    Parameters\\n    ----------\\n    t : float\\n        The number of seconds\\n\\n</td>\n",
       "      <td>config['VUE_CONFIGURATION']))\\n    if not target:\\n        raise ValueError('Can not find resource from configuration.')\\n    target = target[0]\\n    use_minified = (isinstance(use_minified, bool) and use_minified) or current_app.config['VUE_USE_MINIFIED']\\n    CdnClass = LocalCDN if target['use_local'] else getattr(cdn, target['cdn'], CDN)\\n    resource_url = CdnClass(name=name, version=target.get('version', ''),\\n                            use_minified=use_minified).get_resource_url()\\n    if resource_url.startswith('//') and current_app.config['VUE_CDN_FORCE_SSL']:\\n        resource_url = 'https:%s' % resource_url\\n    return resource_url\\n\\ndef humantime(time):\\n    \"\"\"Converts a time in seconds to a reasonable human readable time\\n\\n    Parameters\\n    ----------\\n    t : float\\n        The number of seconds\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15' class='' max='15', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15/15 12:56<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>async def ensure_open(self) -&gt; None:\\n    \"\"\"\\n    Check that the WebSocket connection is open.\\n\\n    Raise :exc:`~websockets.exceptions.ConnectionClosed` if it isn't.\\n\\n    \"\"\"\\n    # Handle cases from most common to least common for performance.\\n    if self.state is State.OPEN:\\n        # If self.transfer_data_task exited without a closing handshake,\\n        # self.close_connection_task may be closing it, going straight\\n        # from OPEN to CLOSED.\\n        if self.transfer_data_task.done():\\n            await asyncio.shield(self.close_connection_task)\\n            raise ConnectionClosed(\\n                self.close_code, self.close_reason\\n</td>\n",
       "      <td>ync def ensure_open(self) -&gt; None:\\n    \"\"\"\\n    Check that the WebSocket connection is open.\\n\\n    Raise :exc:`~websockets.exceptions.ConnectionClosed` if it isn't.\\n\\n    \"\"\"\\n    # Handle cases from most common to least common for performance.\\n    if self.state is State.OPEN:\\n        # If self.transfer_data_task exited without a closing handshake,\\n        # self.close_connection_task may be closing it, going straight\\n        # from OPEN to CLOSED.\\n        if self.transfer_data_task.done():\\n            await asyncio.shield(self.close_connection_task)\\n            raise ConnectionClosed(\\n                self.close_code, self.close_reason\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mq_channel.queue_delete(queue=self._hb_response_q)\\n            mq_channel.queue_delete(queue=self._hb_request_q)\\n\\n            mq_connection.close()\\n\\n\\ndef terminate_manager(self):\\n    \"\"\"\\n    **Purpose**: Method to terminate the tmgr process. This method is\\n    blocking as it waits for the tmgr process to terminate (aka join).\\n    \"\"\"\\n\\n    try:\\n\\n        if self._tmgr_process:\\n\\n            if not self._tmgr_terminate.is_set():\\n                self._tmgr_terminate.set()\\n\\n            if self.check_manager():\\n                self._tmgr_process.join()\\n\\n</td>\n",
       "      <td>mq_channel.queue_delete(queue=self._hb_response_q)\\n            mq_channel.queue_delete(queue=self._hb_request_q)\\n\\n            mq_connection.close()\\n\\n\\ndef terminate_manager(self):\\n    \"\"\"\\n    **Purpose**: Method to terminate the tmgr process. This method is\\n    blocking as it waits for the tmgr process to terminate (aka join).\\n    \"\"\"\\n\\n    try:\\n\\n        if self._tmgr_process:\\n\\n            if not self._tmgr_terminate.is_set():\\n                self._tmgr_terminate.set()\\n\\n            if self.check_manager():\\n                self._tmgr_process.join()\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XTY, XTDY, XTFY, X0TX0, X0TDX0, X0TFX0,\\n                  XTX0, XTDX0, XTFX0, X0TY, X0TDY, X0TFY,\\n                  current_logSNR2, l_idx, n_C,\\n                  n_T, n_V, n_run, n_X0, idx_param_fitU, rank),\\n            method=self.optimizer, jac=True, tol=tol,\\n            options=self.minimize_options)\\n        current_vec_U_chlsk_l = \\\\n            res_fitU.x[idx_param_fitU['Cholesky']]\\n        current_a1 = res_fitU.x[idx_param_fitU['a1']]\\n        norm_fitUchange = np.linalg.norm(res_fitU.x - param0_fitU)\\n</td>\n",
       "      <td>XTY, XTDY, XTFY, X0TX0, X0TDX0, X0TFX0,\\n                  XTX0, XTDX0, XTFX0, X0TY, X0TDY, X0TFY,\\n                  current_logSNR2, l_idx, n_C,\\n                  n_T, n_V, n_run, n_X0, idx_param_fitU, rank),\\n            method=self.optimizer, jac=True, tol=tol,\\n            options=self.minimize_options)\\n        current_vec_U_chlsk_l = \\\\n            res_fitU.x[idx_param_fitU['Cholesky']]\\n        current_a1 = res_fitU.x[idx_param_fitU['a1']]\\n        norm_fitUchange = np.linalg.norm(res_fitU.x - param0_fitU)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_attention.attention_bias_lower_triangle(\\n                common_layers.shape_list(targets)[1]))\\n    decoder_input = common_layers.shift_right_3d(targets)\\n    if hparams.pos == \"timing\":\\n        decoder_input = common_attention.add_timing_signal_1d(decoder_input)\\n    return (decoder_input, decoder_self_attention_bias)\\n\\n\\ndef attention_lm_decoder(decoder_input,\\n                         decoder_self_attention_bias,\\n                         hparams,\\n                         name=\"decoder\"):\\n    \"\"\"A stack of attention_lm layers.\\n\\n    Args:\\n      decoder_input: a Tensor\\n      decoder_self_attention_bias: bias Tensor</td>\n",
       "      <td>attention.attention_bias_lower_triangle(\\n                common_layers.shape_list(targets)[1]))\\n    decoder_input = common_layers.shift_right_3d(targets)\\n    if hparams.pos == \"timing\":\\n        decoder_input = common_attention.add_timing_signal_1d(decoder_input)\\n    return (decoder_input, decoder_self_attention_bias)\\n\\n\\ndef attention_lm_decoder(decoder_input,\\n                         decoder_self_attention_bias,\\n                         hparams,\\n                         name=\"decoder\"):\\n    \"\"\"A stack of attention_lm layers.\\n\\n    Args:\\n      decoder_input: a Tensor\\n      decoder_self_attention_bias: bias Tensor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,\\n            'additional_parameter': None,\\n            'linkname':'surface_sample',\\n            'docstring': \"surface sample generated by zeo++\",\\n        },\\n        \"cell\": {\\n            'valid_types': SinglefileData,\\n            'additional_parameter': None,\\n            'linkname': 'cell',\\n            'docstring': \"cell file containing cell vectors\",\\n        },\\n    })\\n    return use_dict\\n\\n\\ndef _validate_inputs(self, inputdict):\\n    \"\"\" Validate input links.\\n    \"\"\"\\n    #</td>\n",
       "      <td>\\n            'additional_parameter': None,\\n            'linkname':'surface_sample',\\n            'docstring': \"surface sample generated by zeo++\",\\n        },\\n        \"cell\": {\\n            'valid_types': SinglefileData,\\n            'additional_parameter': None,\\n            'linkname': 'cell',\\n            'docstring': \"cell file containing cell vectors\",\\n        },\\n    })\\n    return use_dict\\n\\n\\ndef _validate_inputs(self, inputdict):\\n    \"\"\" Validate input links.\\n    \"\"\"\\n    #</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, \n",
    "                loss_func=CrossEntropyLossFlat(), \n",
    "                cbs=[DropOutput,TerminateOnNaNCallback()], \n",
    "                metrics=[Perplexity(),accuracy]\n",
    "               ).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [15.721566200256348,6726504.5,0.3398023843765259]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForMaskedLM(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForMaskedLM (Input shape: ['8 x 512'])\n",
      "================================================================\n",
      "Layer (type)         Output Shape         Param #    Trainable \n",
      "================================================================\n",
      "Embedding            8 x 512 x 768        38,603,520 True      \n",
      "________________________________________________________________\n",
      "Embedding            8 x 512 x 768        394,752    True      \n",
      "________________________________________________________________\n",
      "Embedding            8 x 512 x 768        768        True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 768              590,592    True      \n",
      "________________________________________________________________\n",
      "Tanh                 8 x 768              0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 50265      38,653,785 True      \n",
      "________________________________________________________________\n",
      "\n",
      "Total params: 163,891,545\n",
      "Total trainable params: 163,891,545\n",
      "Total non-trainable params: 0\n",
      "\n",
      "Optimizer used: <function Adam at 0x7f40970056a8>\n",
      "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
      "\n",
      "Model unfrozen\n",
      "\n",
      "Callbacks:\n",
      "  - DropOutput\n",
      "  - TerminateOnNaNCallback\n",
      "  - ModelToHalf\n",
      "  - TrainEvalCallback\n",
      "  - Recorder\n",
      "  - ProgressCallback\n",
      "  - MixedPrecision\n"
     ]
    }
   ],
   "source": [
    "print(learn.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.00020892962347716094, lr_steep=9.999999747378752e-06)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>1.003952</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>3:09:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def get_vid_from_url(url):\\n    \"\"\"Extracts video ID from URL.\\n    \"\"\"\\n    return match1(url, r'youtu\\.be/([^?/]+)') or \\\\n        match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/v/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\\n        parse_query_param(url, 'v') or \\\\n        parse_query_param(parse_query_param(url, 'u'), 'v')\\n\\n\\ndef sina_xml_to_url_list(xml_data):\\n    \"\"\"str-&gt;list\\n    Convert XML to URL List.\\n    From Biligrab.\\n    \"\"\"\\n    rawurl = []\\n    dom = parseString(xml_data)\\n    for node in dom.getElement...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text\n",
       "0  def get_vid_from_url(url):\\n    \"\"\"Extracts video ID from URL.\\n    \"\"\"\\n    return match1(url, r'youtu\\.be/([^?/]+)') or \\\\n        match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/v/([^/?]+)') or \\\\n        match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\\n        parse_query_param(url, 'v') or \\\\n        parse_query_param(parse_query_param(url, 'u'), 'v')\\n\\n\\ndef sina_xml_to_url_list(xml_data):\\n    \"\"\"str->list\\n    Convert XML to URL List.\\n    From Biligrab.\\n    \"\"\"\\n    rawurl = []\\n    dom = parseString(xml_data)\\n    for node in dom.getElement..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('fine_tuned')\n",
    "learn.save('20200824_fit_head_roberta_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('20200824_fit_head_roberta_model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A unicorn is a magical creature with a rainbow tail and a horn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.model.generate(inp, max_length=40, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>A unicorn is a magical creature with a rainbow tail and a horn</s>AAAAAAAAAAAAAAAAAAAAAAAAA'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())\n",
    "# tokenizer.decode(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   250, 35545,    16,    10, 13867, 20397,    19,    10, 20927,\n",
       "          7886,     8,    10, 21305,     2,   250,   250,   250,   250,   250,\n",
       "           250,   250,   250,   250,   250,   250,   250,   250,   250,   250,\n",
       "           250,   250,   250,   250,   250,   250,   250,   250,   250,   250]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,   250, 35545,    16,    10, 13867, 20397,    19,    10, 20927,\n",
       "         7886,     8,    10, 21305,     2,   250,   250,   250,   250,   250,\n",
       "          250,   250,   250,   250,   250,   250,   250,   250,   250,   250,\n",
       "          250,   250,   250,   250,   250,   250,   250,   250,   250,   250],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>import</s>importimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimport'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"import\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "inp.shape\n",
    "preds = learn.model.generate(inp, max_length=40, num_beams=5, temperature=1.5)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>import <MASK> from</s>importimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimportimport'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"import <MASK> from\"\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None].cuda()\n",
    "inp.shape\n",
    "preds = learn.model.generate(inp, max_length=40, num_beams=5, temperature=1.5)\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('20200824_roberta-CodeSearchNet_fit_head/vocab.json',\n",
       " '20200824_roberta-CodeSearchNet_fit_head/merges.txt',\n",
       " '20200824_roberta-CodeSearchNet_fit_head/special_tokens_map.json',\n",
       " '20200824_roberta-CodeSearchNet_fit_head/added_tokens.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model_roberta = learn.model\n",
    "# save tokenizer and model\n",
    "model_path= '20200824_roberta-CodeSearchNet_fit_head'\n",
    "!mkdir {model_path}\n",
    "_model_roberta.save_pretrained(f\"{str(model_path)}\")\n",
    "tokenizer.save_pretrained(f\"{str(model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>from pandas import.</s>',\n",
       "  'score': 0.9145868420600891,\n",
       "  'token': 4,\n",
       "  'token_str': '.'},\n",
       " {'sequence': '<s>from pandas import.</s>',\n",
       "  'score': 0.015848614275455475,\n",
       "  'token': 479,\n",
       "  'token_str': '.'},\n",
       " {'sequence': '<s>from pandas importfrom</s>',\n",
       "  'score': 0.0070899128913879395,\n",
       "  'token': 7761,\n",
       "  'token_str': 'from'},\n",
       " {'sequence': '<s>from pandas import,</s>',\n",
       "  'score': 0.0038756707217544317,\n",
       "  'token': 6,\n",
       "  'token_str': ','},\n",
       " {'sequence': '<s>from pandas import from</s>',\n",
       "  'score': 0.0038681819569319487,\n",
       "  'token': 31,\n",
       "  'token_str': 'from'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"./20200824_roberta-CodeSearchNet_fit_head\",\n",
    "    tokenizer=\"./20200824_roberta-CodeSearchNet_fit_head\"\n",
    ")\n",
    "\n",
    "fill_mask(\"from pandas import <mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>1.003831</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>3:10:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>1.003558</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>3:11:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>1.003384</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>3:11:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>1.003221</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>3:11:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>1.003128</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>3:12:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>1.003091</td>\n",
       "      <td>0.999446</td>\n",
       "      <td>3:13:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>3:12:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>1.002956</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>3:11:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014581</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>1.002929</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>3:11:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010569</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>1.002925</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>3:11:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('20200824_roberta-CodeSearchNet-fine-tuned/vocab.json',\n",
       " '20200824_roberta-CodeSearchNet-fine-tuned/merges.txt',\n",
       " '20200824_roberta-CodeSearchNet-fine-tuned/special_tokens_map.json',\n",
       " '20200824_roberta-CodeSearchNet-fine-tuned/added_tokens.json')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('20200824_fine_tuned_roberta_model')\n",
    "_model_roberta_fine = learn.model\n",
    "# save tokenizer and model\n",
    "model_path= '20200824_roberta-CodeSearchNet-fine-tuned'\n",
    "!mkdir {model_path}\n",
    "_model_roberta_fine.save_pretrained(f\"{str(model_path)}\")\n",
    "tokenizer.save_pretrained(f\"{str(model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForMaskedLM (Input shape: ['8 x 512'])\n",
      "================================================================\n",
      "Layer (type)         Output Shape         Param #    Trainable \n",
      "================================================================\n",
      "Embedding            8 x 512 x 768        38,603,520 True      \n",
      "________________________________________________________________\n",
      "Embedding            8 x 512 x 768        394,752    True      \n",
      "________________________________________________________________\n",
      "Embedding            8 x 512 x 768        768        True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 12 x 512 x 512   0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 3072       2,362,368  True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        2,360,064  True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Dropout              8 x 512 x 768        0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 768              590,592    True      \n",
      "________________________________________________________________\n",
      "Tanh                 8 x 768              0          False     \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 768        590,592    True      \n",
      "________________________________________________________________\n",
      "LayerNorm            8 x 512 x 768        1,536      True      \n",
      "________________________________________________________________\n",
      "Linear               8 x 512 x 50265      38,653,785 True      \n",
      "________________________________________________________________\n",
      "\n",
      "Total params: 163,891,545\n",
      "Total trainable params: 163,891,545\n",
      "Total non-trainable params: 0\n",
      "\n",
      "Optimizer used: <function Adam at 0x7f40970056a8>\n",
      "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
      "\n",
      "Model unfrozen\n",
      "\n",
      "Callbacks:\n",
      "  - DropOutput\n",
      "  - TerminateOnNaNCallback\n",
      "  - ModelToHalf\n",
      "  - TrainEvalCallback\n",
      "  - Recorder\n",
      "  - ProgressCallback\n",
      "  - MixedPrecision\n"
     ]
    }
   ],
   "source": [
    "print(learn.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>from pandas import\\n</s>',\n",
       "  'score': 0.6224209666252136,\n",
       "  'token': 50118,\n",
       "  'token_str': ''},\n",
       " {'sequence': '<s>from pandas import.</s>',\n",
       "  'score': 0.22222988307476044,\n",
       "  'token': 4,\n",
       "  'token_str': '.'},\n",
       " {'sequence': '<s>from pandas import </s>',\n",
       "  'score': 0.038354743272066116,\n",
       "  'token': 1437,\n",
       "  'token_str': ''},\n",
       " {'sequence': '<s>from pandas import\\n\\n</s>',\n",
       "  'score': 0.028566861525177956,\n",
       "  'token': 50140,\n",
       "  'token_str': ''},\n",
       " {'sequence': '<s>from pandas import.</s>',\n",
       "  'score': 0.021909384056925774,\n",
       "  'token': 479,\n",
       "  'token_str': '.'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"./20200824_roberta-CodeSearchNet-fine-tuned\",\n",
    "    tokenizer=\"./20200824_roberta-CodeSearchNet-fine-tuned\"\n",
    ")\n",
    "\n",
    "fill_mask(\"from pandas import <mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Generation is currently not supported for RobertaForMaskedLM. Please select a model from ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel'] for generation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-35d84976fbcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtext_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from pandas import <mask>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, return_tensors, return_text, clean_up_tokenization_spaces, *args, **generate_kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m             raise NotImplementedError(\n\u001b[1;32m    645\u001b[0m                 \"Generation is currently not supported for {}. Please select a model from {} for generation.\".format(\n\u001b[0;32m--> 646\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_MODELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m                 )\n\u001b[1;32m    648\u001b[0m             )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Generation is currently not supported for RobertaForMaskedLM. Please select a model from ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel'] for generation."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generation = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"./20200824_roberta-CodeSearchNet-fine-tuned\",\n",
    "    tokenizer=\"./20200824_roberta-CodeSearchNet-fine-tuned\"\n",
    ")\n",
    "\n",
    "text_generation(\"from pandas import <mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
